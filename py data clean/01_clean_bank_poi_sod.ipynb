{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "from global_variables import *\n",
    "import urllib.request\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "# this function uses USPS api to get the verified USPS address\n",
    "def get_usps_address(street, city, state, zip):\n",
    "    xml_string = (\n",
    "        '<?xml version=\"1.0\"?>\\n'\n",
    "        '<AddressValidateRequest USERID=\"33LOUIS8M0561\">\\n'\n",
    "        '    <Revision>1</Revision>\\n'\n",
    "        '    <Address ID=\"0\">\\n'\n",
    "        f'        <Address1>{street}</Address1>\\n'\n",
    "        '        <Address2></Address2>\\n'\n",
    "        f'        <City>{city}</City>\\n'\n",
    "        f'        <State>{state}</State>\\n'\n",
    "        f'        <Zip5>{zip}</Zip5>\\n'\n",
    "        '        <Zip4/>\\n'\n",
    "        '    </Address>\\n'\n",
    "        '</AddressValidateRequest>'\n",
    "    )\n",
    "    xml_string = xml_string.replace('\\n', '').replace('\\t', '')\n",
    "    xml_string = urllib.parse.quote_plus(xml_string)\n",
    "    xml_string = \"http://production.shippingapis.com/ShippingAPI.dll?API=Verify&XML=\" + xml_string\n",
    "    response = urllib.request.urlopen(xml_string)\n",
    "    if response.getcode() == 200:\n",
    "        contents = response.read()\n",
    "        return contents\n",
    "    else:\n",
    "        return 'error'\n",
    "\n",
    "\n",
    "results = requests.get(url=POI_Data_PRODUCT_API_PATH,\n",
    "                       params={},  # optionally set date value here\n",
    "                       headers={'X-API-KEY': API_KEY,\n",
    "                                'accept': 'application/json'\n",
    "                                })\n",
    "response_json = results.json()\n",
    "## Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "poi_csv_path = 'C:/Users/dratnadiwakara2/Documents/OneDrive - Louisiana State University/Raw Data/Dewey/poi_us_banks.csv'\n",
    "# for link_data in response_json['download_links']:\n",
    "# \n",
    "#     print(f\"Downloading file {link_data['file_name']}...\")\n",
    "# \n",
    "#     df = pd.read_csv(BytesIO(requests.get(link_data['link']).content), compression=\"gzip\")\n",
    "#     df = df[df['ISO_COUNTRY_CODE'] == 'US'][['CATEGORY_TAGS', 'CITY', 'LATITUDE','LONGITUDE','NAICS_CODE','PLACEKEY','POSTAL_CODE','REGION','STREET_ADDRESS','SUB_CATEGORY','TOP_CATEGORY','LOCATION_NAME']]\n",
    "#     df = df[(df['TOP_CATEGORY'] == 'Depository Credit Intermediation') | (df['NAICS_CODE'].astype(str).str[:3] == '522')]\n",
    "#     df = df.reset_index()\n",
    "# \n",
    "#     if os.path.isfile(poi_csv_path):\n",
    "#         header_option = False  \n",
    "#     else:\n",
    "#         header_option = True  \n",
    "# \n",
    "#     df.to_csv(poi_csv_path, mode='a', header=header_option, index=False)\n",
    "# \n",
    "# df = pd.read_csv(poi_csv_path)    \n",
    "# \n",
    "# with gzip.open(poi_csv_path+\".gz\", 'wt', encoding='utf-8') as gzipped_file:\n",
    "#     df.to_csv(gzipped_file, index=False)\n",
    "with gzip.open(poi_csv_path + \".gz\", 'rt', encoding='utf-8') as gzipped_file:\n",
    "    poi = pd.read_csv(gzipped_file)\n",
    "\n",
    "poi = poi.reset_index()\n",
    "poi['POSTAL_CODE'] = poi['POSTAL_CODE'].astype(int)\n",
    "poi['full_address_poi'] = poi['STREET_ADDRESS'].str.lower() + \", \" + poi['CITY'].str.lower() + \", \" + poi[\n",
    "    'POSTAL_CODE'].astype(str) + \" \" + poi['REGION'].str.lower()\n",
    "poi['usps_contents'] = ''\n",
    "poi = poi.reset_index(drop=True)\n",
    "\n",
    "output_file_path = \"C:/Users/dratnadiwakara2/Documents/OneDrive - Louisiana State University/Raw Data/Dewey/poi_full_address.csv\"\n",
    "with tqdm(total=(len(poi) - 28871)) as pbar:\n",
    "    with open(output_file_path, \"a\") as output_file:\n",
    "        for index in range(28871, len(poi)):\n",
    "            row = poi.iloc[index]\n",
    "            num_rows = len(poi)\n",
    "            break_interval = 400\n",
    "\n",
    "            if (index + 1) % break_interval == 0 and index != (num_rows - 1):\n",
    "                time.sleep(1)  # Sleep for one second\n",
    "\n",
    "            try:\n",
    "                op = get_usps_address(row['STREET_ADDRESS'], row['CITY'], row['REGION'], row['POSTAL_CODE'])\n",
    "                poi.loc[index, 'usps_contents'] = op\n",
    "                output_file.write(f\"{row['full_address_poi']}|{index}|{op}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"An exception occurred: {e}\")\n",
    "                break\n",
    "            pbar.update(1)\n",
    "poi['usps_address'] = ''\n",
    "with tqdm(total=len(poi)) as pbar:\n",
    "    for index, row in poi.iterrows():\n",
    "        root = ET.fromstring(poi.loc[index, 'usps_contents'])\n",
    "        if len(root.findall(\"Address\")) == 1:\n",
    "            try:\n",
    "                add_xml = root.findall(\"Address\")[0]\n",
    "                add_text = add_xml.find(\"Address2\").text + \" \" + add_xml.find(\"City\").text + \" \" + add_xml.find(\n",
    "                    \"State\").text + \" \" + add_xml.find(\"Zip5\").text\n",
    "                if add_xml.find(\"Address1\") is not None:\n",
    "                    add_text = add_text + \" \" + add_xml.find(\"Address1\").text\n",
    "                poi.loc[index, 'usps_address'] = add_text\n",
    "            except:\n",
    "                pass\n",
    "        pbar.update(1)\n",
    "output_file_path = \"C:/Users/dratnadiwakara2/Documents/OneDrive - Louisiana State University/Raw Data/Dewey/poi_with_usps_address.csv.gz\"\n",
    "with gzip.open(output_file_path, 'wt', encoding='utf-8') as gzipped_file:\n",
    "    poi.to_csv(gzipped_file, index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "835317b1a89399d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "## SOD Data\n",
    "sod_files_path = 'C:/Users/dratnadiwakara2/Documents/OneDrive - Louisiana State University/Raw Data/SOD/data/'\n",
    "\n",
    "sod_data = ['ALL_2019.csv', 'ALL_2020.csv', 'ALL_2021.csv', 'ALL_2022.csv', 'ALL_2023.csv']\n",
    "\n",
    "sod_data_files = [sod_files_path + s for s in sod_data]\n",
    "\n",
    "selected_columns = ['YEAR', 'CERT', 'BRNUM', 'UNINUMBR', 'NAMEFULL', 'ADDRESBR', 'CITYBR', 'CNTYNAMB', 'STALPBR',\n",
    "                    'ZIPBR', 'NAMEBR', 'SIMS_LATITUDE', 'SIMS_LONGITUDE']\n",
    "\n",
    "combined_df = pd.DataFrame(columns=selected_columns)\n",
    "\n",
    "for csv_file in sod_data_files:\n",
    "    df = pd.read_csv(csv_file, encoding='latin-1')\n",
    "    selected_df = df[selected_columns]\n",
    "    combined_df = pd.concat([combined_df, selected_df], ignore_index=True)\n",
    "\n",
    "combined_df = combined_df.reset_index()\n",
    "sod_data_branches = combined_df.drop_duplicates(subset=['UNINUMBR'])\n",
    "sod_data_branches = sod_data_branches.reset_index()\n",
    "sod_data_branches['full_address_sod'] = sod_data_branches['ADDRESBR'].str.lower() + \", \" + sod_data_branches[\n",
    "    'CITYBR'].str.lower() + \", \" + sod_data_branches['ZIPBR'].astype(str) + \" \" + sod_data_branches[\n",
    "                                            'STALPBR'].str.lower()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a263228085e3d5a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sod_data_branches['usps_contents'] = ''\n",
    "sod_data_branches = sod_data_branches.reset_index(drop=True)\n",
    "\n",
    "output_file_path = \"C:/Users/dratnadiwakara2/Documents/OneDrive - Louisiana State University/Raw Data/Dewey/sod_full_address.csv\"\n",
    "\n",
    "with tqdm(total=len(sod_data_branches)) as pbar:\n",
    "    with open(output_file_path, \"a\") as output_file:\n",
    "        for index, row in sod_data_branches.iterrows():\n",
    "            num_rows = len(sod_data_branches)\n",
    "            break_interval = 400\n",
    "\n",
    "            if (index + 1) % break_interval == 0 and index != (num_rows - 1):\n",
    "                time.sleep(1)  # Sleep for one second\n",
    "\n",
    "            try:\n",
    "                op = get_usps_address(row['ADDRESBR'], row['CITYBR'], row['STALPBR'], row['ZIPBR'])\n",
    "                sod_data_branches.loc[index, 'usps_contents'] = op\n",
    "                output_file.write(f\"{row['full_address_sod']}|{index}|{op}\\n\")\n",
    "            except:\n",
    "                print('error')\n",
    "                break\n",
    "            pbar.update(1)\n",
    "sod_data_branches['usps_address'] = ''\n",
    "with tqdm(total=len(sod_data_branches)) as pbar:\n",
    "    for index, row in sod_data_branches.iterrows():\n",
    "        root = ET.fromstring(sod_data_branches.loc[index, 'usps_contents'])\n",
    "        if len(root.findall(\"Address\")) == 1:\n",
    "            try:\n",
    "                add_xml = root.findall(\"Address\")[0]\n",
    "                add_text = add_xml.find(\"Address2\").text + \" \" + add_xml.find(\"City\").text + \" \" + add_xml.find(\n",
    "                    \"State\").text + \" \" + add_xml.find(\"Zip5\").text\n",
    "                if add_xml.find(\"Address1\") is not None:\n",
    "                    add_text = add_text + \" \" + add_xml.find(\"Address1\").text\n",
    "                sod_data_branches.loc[index, 'usps_address'] = add_text\n",
    "            except:\n",
    "                pass\n",
    "        pbar.update(1)\n",
    "        \n",
    "output_file_path = \"C:/Users/dratnadiwakara2/Documents/OneDrive - Louisiana State University/Raw Data/Dewey/sod_data_branches_with_usps_address.csv.gz\"\n",
    "with gzip.open(output_file_path, 'wt', encoding='utf-8') as gzipped_file:\n",
    "    sod_data_branches.to_csv(gzipped_file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6ada24e12551f03"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
